---
title: "SHIPS Tropical Cyclone Data Set"
author: "Sarah M. Reehl"
date: "January 27, 2016"
header-includes:
  - \usepackage{bm}
output:
html_document:
bibliography: tc_ships.bib
---

## Background
The [Tropical Cyclones Developmental Dataset](http://rammb.cira.colostate.edu/research/tropical_cyclones/ships/developmental_data.asp) was used to develop the [Statistical Hurricane Intensity Prediction Scheme](http://rammb.cira.colostate.edu/research/tropical_cyclones/ships/) (SHIPS) for predicting changes in tropical cyclone (TC) intensities (@DeMaria1994SHIPS). The National Hurricane Center (NHC) uses SHIPS, along with other models, to generate predictions and guide official track and intensity forecasts @NHC2009. Traditionally, SHIPS forecasts have outperformed climatology and persistence forecasts since circa 1997. However, SHIPS has not performed well in Rapid Intensification (RI) events, defined as a rapid increase in maximum windspeed over 24 hours exceeding 30, 35, or 40 knots as described in @kaplan2003large. 

## Data Description
Focusing on TCs from the Atlantic Basin only, the raw data arrives in a file called *lsdiaga_1982_2014_rean_sat_nbc_ts.dat* which is described as Atlantic data with SHIPS predictors from either re-analysis or operational analysis with satellite variables when available. The file is one concatenated list of record sets for each storm case. Here, a case includes a current time observation (hour 0) in addition to 120 hours of forecast information (hours 6 to 120) and, in some cases, 12 hours of past information (hours -12 to -6). The case time points occur in 6 hour intervals. Each of the different cases begin with a line descriptor called **HEAD** and end with an end-line called **LAST**. Not all predictors are available for all years. To make the *.dat* file in a readable format, we treated each record as a fixed width format (fwf) table, skipping the header rows, with 24 columns of width 5. Once the fwf table was parsed, the table was transposed to place the attributes as columns and time points as rows. The missing value string `9999` is replaced with `NA`s and the parsed, transposed, and cleaned record is written to a `.csv` file for the sake a creating a bank of easily accessible records. As there are multiple records for one TC, the `.csv` file names are written as `uniquestormID.recordnumber.csv`. 

The next step in preprocessing the data was to concatenate the **hour 0** observations for each case for each storm. Before adding the observation to a master data frame, we crosschecked observations of corresponding time points. If the cases are recorded correctly, for a given storm hours 0 to 114 of the current case should be equivalent with hours 6 to 120 of the previous case for time dependent predictors. To keep track of case discrepancies, we appended a column call **Match** to the master data frame. Below is a detailed description of each of the raw attributes of the master data frame, mostly adapted from the predictor [description file](http://rammb.cira.colostate.edu/research/tropical_cyclones/ships/developmental_data.asp). 

Attribute Name        | Description
--------------------- | ------------------------
**ID**   | chr. Storm identifier. The first two characters "AL" represent the Atlantic basin, the second two characters represent the sequence number of a TC in a certain year, and the remaining four characters represent the year when the TC happened 
**DATE** | POSIXct. Date of the storm in the format *yymmdd*
**TIMESTAMP** | POSIXct. Date of the storm in the format *yymmdd HH* 
**RECORDNM** | num. The time intervals are currently in fixing. This is the record number from the original .dat file
**VMAX** | int. Maximum wind surface (kts)
**MSLP** | int. Minimum sea level pressure (hPa)
**TYPE** | factor. Storm type type (0=wave, remnant low, dissipating low, 1 = tropical, 2 = subtropical, NA = extra-tropical).        
**HIST20**-**HIST120** | int. Number of 6 hour periods that the storm max wind has been above 20, 25, ... 120 kts.
**DELV** | int. Intensity change relative to the storm start (kts)
**INCV** | int. Intensity change relative to the previous 6 hour interval. Set to NA for land mass crossings
**LAT**  | int. The latitude in 10\*degrees North of the approximate storm center
**LON**  | int. The longitude in 10\*degrees West of the approximate storm center
**CSST** | int. Climatological sea surface temperature (deg C\*10)
**CD20** | int. Climatological depth (m) of 20 degree isotherm from 2005-2010 NCODA analyses
**CD26** | int. Climatological depth (m) of 26 degree isotherm from 2005-2010 NCODA analyses
**COHC** | int. Climatological ocean heat content (kJ/cm^2) 2005-2010 NCODA analyses
**DTL**  | int. Distance to nearest major land mass (km)
**RSST** | int. Reynolds sea surface temperature ( deg C\*10)
**PCHN** | int. Estimated ocean heat content(kJ/cm^2) from **COHC** and current sea surface temperature anomaly. Designed to fill in missing **RHCN**
**U200** | int. 200 hPa zonal wind speed (10\*kts) for r = 200-800 km on average
**U20C** | int. 200 hPa zonal wind speed (10\*kts) for r = 0-500 km on average
**V20C** | int. Vertical component of 200 hPa zonal wind speed(10\*kts) for r = 200-800 km on average 
**E000** | int. 1000 hPa equivalent potential temperature, $\theta_e$ for r = 200-800 km on average (K)
**EPOS** | int. Average $\theta_e$ difference between a parcel lifted from the surface and its environment for r = 200-800 km on average (K)
**ENEG** | int. Negative average $\theta_e$ difference between a parcel lifted from the surface and its environment for r = 200-800 km on average, sign not included (K)
**EPSS**| int. Negative average $\theta_e$ difference between a parcel lifted from the surface and its environment for r = 200-800 km on average, sign not included with $\theta_e$ compared with the saturated $\theta_e$ of the environment (K)
**ENSS** | int. Negative average $\theta_e$ difference between a parcel lifted from the surface and its environment for r = 200-800 km on average, sign not included with $\theta_e$ compared with the saturated $\theta_e$ of the environment (K)
**RHLO** | int. 850-700 hPa relative humidity(\%) for 200-800 km
**RHMD** | int. 700-500 hPa relative humidity(\%) for 200-800 km
**RHHI** | int. 500-300 relative humidity(\%) for 200-800 km
**PSLV**| int. Pressure of the center of mass of the layer where the storm motion best matches environmental flo. Used to calculate steering pressure as well (hPa)
**Z850** | int. 850 hPa vorticity ($sec^{-1}*10^7$) for r = 0-1000 km
**D200** | int. 200 hPa divergence ($sec^{-1}*10^7$) for r = 0-1000 km
**REFC** | int. Relative eddy momentum flux convergence ($m/s/day$) for r = 100-600 km on average
**PEFC** | int. Planetary eddy momentum flux convergence ($m/s/day$) for r = 100-600 km on average
**T000** | int. 1000 hPa temperature (deg C\*10) 200-800 km average
**R000** | int. 1000 hPa relative humidity 200-800 km average
**Z000** | int. 1000 hPa height deviation (m) from the U.S. standard atmosphere
**TLAT** | int. Latitude of 850 hPa vortex center in NCEP analysis (10\*deg N)
**TLON** | int. Longitude of 850 hPa vortex center in NCEP analysis (10\*deg N)
**TWAC** | int. Symmetric tangential wind at 850 hPa from NCEP analysis 0-600 kn average ($m/sec*10$)
**TWXC** | int. Maximum 850 hPa symmetric tangential wind at 850 hPa from NCEP analysis ($m/sec*10$)
**G150** | int. Temperature perturbation at 150 hPa due to the symmetric vortex calculated from gradient thermal wind. Averaged from r=200 to 800 km center on input lat and lon (not always the model/analysis vortex position) (deg C\*10) 
**G200** | int. Temperature perturbation at 200 hPa due to the symmetric vortex calculated from gradient thermal wind. Averaged from r=200 to 800 km center on input lat and lon (not always the model/analysis vortex position) (deg C\*10) 
**G250** | int. Temperature perturbation at 250 hPa due to the symmetric vortex calculated from gradient thermal wind. Averaged from r=200 to 800 km center on input lat and lon (not always the model/analysis vortex position) (deg C\*10) 
**V000** | int. Tangential wind azimuthally averaged at r=500 km from (TLAT,TLON) If TLAT,TLON are not available, (LAT,LON) are used ($m/sec*10$)  
**V850** | int. 850 hPa tangential wind azimuthally averaged at r=500 km from (TLAT,TLON) If TLAT,TLON are not available, (LAT,LON) are used ($m/sec*10$)  
**V500** | int. 500 hPa tangential wind azimuthally averaged at r=500 km from (TLAT,TLON) If TLAT,TLON are not available, (LAT,LON) are used ($m/sec*10$)  
**V300** | int. 300 hPa tangential wind azimuthally averaged at r=500 km from (TLAT,TLON) If TLAT,TLON are not available, (LAT,LON) are used ($m/sec*10$)  
**TGRD** | int. Magnitude of the temperature gradient between 850 and 700 hPa averaged from 0 to 500 km estimated from the geostrophic thermal wind ($degC/m*10^7$) 
**TADV** | int. The temperature advection between 850 and 700 hPa averaged from 0 to 500 km from the geostrophic thermal wind ($degC/sec*10^6$) 
**PENC** | int. Azimuthally averaged surface pressure at outer edge of vortex $( (hPa-1000)*10)$
**SHDC** | int. Shear magnitude (kts\*10) vs time (200-800 km) with vortex removed and averaged from 0-500 km relative to 850 hPa vortex center
**SDDC** | int. Heading in degrees of above shear vector where westerly shear is valued at 90 degrees
**SHGC** | int. Generalized 850â€“200 hPa shear magnitude (kts\*10) (takes into account all levels) with vortex removed and averaged from 0-500 km relative to 850 hPa vortex center
**DIVC** | int. Divergence ($sec^{-1}*10^7$) for r = 0-1000 km centered at 850 hPa vortex location
**T150** | int. 150 hPa temperature (deg C\*10) versus time 200 to 800 km
**T200** | int. 200 hPa temperature (deg C\*10) versus time 200 to 800 km 
**T250** | int. 250 hPa temperature (deg C\*10) versus time 200 to 800 km
**SHRD** | int. 850-200 hPa shear magnitude (kts\*10) vs time 200-800 km
**SHRS** | int. 850-500 hPa shear magnitude (kts\*10) 
**SHTS** | int. Heading above sheer vector (deg)
**SHRG** | int. Generalized 850-200 hPa shear magnitude (kts\*10) (takes into account all levels)
**PENV** | int. 200 to 800 km average surface pressure $((hPa-1000)*10)$
**VMPI** | int. Maximum potential intensity from Kerry Emanuel equation (kts)
**VVAV** | int. Average (0 to 15 km) vertical velocity ($m/s *100$) of a parcel lifted from the surface where entrainment, the ice phase and the condensate weight are accounted for. Source note: Moisture and temperature biases between the operational and reanalysis files make this variable inconsistent in the 2001-2007 samples, compared to 2000 and before
**VMFX** | int. VVAV with a density weighted vertical average
**VVAC** | int. VVAV with soundings from 0-500 km with GFS vortex removed  
**HE07** | undefined
**HE05** | undefined
**IRXX** | int. Non-satellite GOES model predictors used to generate IR00
**RD20** | int. Ocean depth of the 20 deg C isotherm (m), from satellite altimetry data
**RD26** | int. Ocean depth of the 26 deg C isotherm (m) from satellite altimetry data
**RHCN** | int. Ocean heat content (KJ/cm2) from satellite altimetry data
**Match** | logical. Crosscheck for a given storm, where hours 0 to 114 of the current case should be equivalent with hours 6 to 120 of the previous case for time dependent predictors
**IR00_AVG_200BT** | int. Average GOES 4 satellite brightness temp r=0-200 km  (deg C \*10)
**IR00_STD_200BT** | int. Standard deviation of GOES 4 satellite brightness temp r=0-200 km (deg C \*10)  
**IR00_AVG_300BT** | int. Average GOES 4 satellite brightness temp  r=100-300 km (deg C \*10)
**IR00_STD_300BT** | int. Standard deviation GOES 4 satellite brightness temp r=100-300 km (deg C \*10) 
**IR00_PCT_AREA_10BT** | int. Percent area r= 50-200 km of GOES 4 brightness temp $<$ -10 C 
**IR00_PCT_AREA_20BT** | int.  Percent area r= 50-200 km of GOES 4 brightness temp $<$ -20 C 
**IR00_PCT_AREA_30BT** |  Percent area r= 50-200 km of GOES 4 brightness temp $<$ -30 C 
**IR00_PCT_AREA_40BT** | int. Percent area r= 50-200 km of GOES 4 brightness temp $<$ -40 C 
**IR00_PCT_AREA_50BT** | int. Percent area r= 50-200 km of GOES 4 brightness temp $<$ -50 C 
**IR00_PCT_AREA_60BT** | int. Percent area r= 50-200 km of GOES 4 brightness temp $<$ -60 C 
**IR00_MAX_BT** | int. Maximum brightness temp r = 0-30 km (deg C \*10)
**IR00_AVG_30BT** | int. Average brightness temp r = 0-30 km (deg C \*10)
**IR00_RADIUS_MAXBT** | int. Radius of maximum brightness temp (km)
**IR00_MIN_20BT** | int. Minimum brightness temp r = 20-120 km (deg C \*10)
**IR00_AVG_20BT** | int. Average brightness temp r = 20-120 km (deg C \*10)
**IR00_RADIUS_MINBT** | int. Radius of minimum brightness temp (km)
**IR3*** | ints. Same as the IR00 vars three hours before initial case time
**JDATE** | int. The absolute value of the Julian date minus the peak date of the season according to @DeMaria1994SHIPS
**POT** | int. The intensification potential, that is **VMPI** - **VMAX** (kts)

## Exploratory Analysis

```{r, echo = FALSE, message = FALSE}
load("~/Documents/Projects/TeMpSA/TeMpSA/SHIPS_Developmental/tcIntermediate.RData")
# fix date
library(lubridate)
tcData$TIMESTAMP <- parse_date_time(tcData$TIMESTAMP, c("ymdhms", "ymd"))
```
Without any further cleaning, the data is ``r nrow(tcData)`` rows of realtime instances and ``r ncol(tcData)`` columns of attributes to each instance. There are ``r length(unique(tcData$ID))`` unique TCs ranging from ``r min(tcData$DATE)`` to ``r max(tcData$DATE)``. The storm paths are again limited to the Atlantic Basin as seen below.


```{r, echo = FALSE, message = FALSE}
library(dplyr)
library(ggplot2)
library(maps)
#Label stroms by RI or nonRI
RI_fun <- function(VMAX_Obs, TIMESTAMP_Obs, cut=30, numeric = FALSE){
  #A storm at time t is RI if its VMAX will be at least 'cut' (e.g. 30)
  #knots greater at time t+24 hours than at time t
  #This function either returns the diff between the VMAX
  #at time t and t+24 (numeric=TRUE) or a binary indicataor
  #if VMAX_diff>cut (numeric=FALSE)
  
  N <- length(VMAX_Obs)
  res <- rep(0,N) 
  
  if ( N > 4) {
    off4 <- TIMESTAMP_Obs[-c(1:4)]
    VMAX_Diff4 <- diff(VMAX_Obs, lag = 4) # differences in VMAX lagged 24
    
    if (numeric) {
      res[-c((N -  3):N)] <- VMAX_Diff4
      
    }else{
      VMAX_Diff4 <- diff(VMAX_Obs, lag = 4)
      VMAX_Diff3 <- diff(VMAX_Obs, lag = 3)
      VMAX_Diff2 <- diff(VMAX_Obs, lag = 2)
      VMAX_Diff1 <- diff(VMAX_Obs, lag = 1)
      
      res[which(VMAX_Diff4 >= cut)] <- 1
      res[which(VMAX_Diff3 >= cut)] <- 1
      res[which(VMAX_Diff2 >= cut)] <- 1
      res[which(VMAX_Diff1 >= cut)] <- 1
    }
    res[which(difftime(off4, TIMESTAMP_Obs[-c((N -  3):N)], units = "hours") != 24)] <- NA # if the storm is out of sequence
  }
  
  return(res)
  
}

#Group all of the data by storm ID
byStorm <- group_by(tcData, ID) %>% mutate(RI = RI_fun(VMAX, TIMESTAMP), VMAX_Diff = RI_fun(VMAX, TIMESTAMP, numeric = TRUE), DELV = (VMAX - first(VMAX)))
# Get rid of redundancies in the original "time independent" attributes
byStorm$HIST <- NULL
byStorm$IR00 <- NULL
byStorm$IRM3 <- NULL
byStorm$LAST <- NULL
byStorm$TIME <- NULL

##Plot all of the storms
tcData$LAT <- tcData$LAT/10
tcData$LON <- tcData$LON/10
world <- map_data("world")
smallworld <- subset(world,long < max(-tcData$LON))
smallworld <- subset(smallworld, long > min(-tcData$LON))
smallworld <- subset(smallworld, lat > min(tcData$LAT))
smallworld <- subset(smallworld, lat < max(tcData$LAT))

qplot(long, lat, data = smallworld) + theme_bw() + geom_path(data = tcData, aes(-LON, LAT, colour = ID, group = ID)) + guides(colour = FALSE) + theme_bw()
```


## Detailed Variable Exploration
## Checks and Inconsistencies
In the cross check for time point inconsistencies, there are a total of ``r length(na.omit(tcData$Match)) - sum(na.omit(tcData$Match))`` inconsistencies. As documented in @jankulak2012prediction, 18 of these inconsistencies belong to the **REFC** attribute. Another 10 of these inconsistencies are due to the **TYPE** attribute. The remaining 10 inconsistencies belong to 9 different storms, where the storm is missing at least one day of data. For example, Hurricane Nadine, the longest storm in this set of records, has a missing cases between 120921 and 120923. We can see the missing data in the lat/long path below
```{r, echo = FALSE, message = FALSE}
NADINE <- subset(byStorm, ID == "AL142012")
qplot(LAT, LON, data = NADINE, geom = 'point', colour = VMAX, main = "Track for Storm AL142012 with Missing Data")
```

Next, a check to see that the storm history variables beginning with **HIST** are in fact a cumulative history. For the first TC, the **HIST** vars look like:
```{r, echo = FALSE, message = FALSE}
library(reshape2)
library(wesanderson)
pal <- wes_palette("Cavalcanti", n = 460, type = "continuous")
histDf <- byStorm[1:17, grep("HIST*", colnames(byStorm))]
histDf$TIME <- byStorm$TIMESTAMP[1:17]
histDf$ID <- byStorm$ID[1:17]
meltedHist <- melt(histDf, id.vars = c("ID", "TIME"))
ggplot(meltedHist, aes(x = TIME, y = value, color = factor(ID) )) +
  geom_line(aes(group = variable)) +
  facet_grid(~variable) +
  scale_color_manual(values = pal) +
  theme_bw()+
  theme(legend.position = "none", axis.text.x = element_text(angle = 50))
  
```  

A little messier, all the storms look like:

```{r, echo = FALSE, message = FALSE}

pal <- wes_palette("Cavalcanti", n = 460, type = "continuous")
histDf <- byStorm[, grep("HIST*", colnames(byStorm))]
histDf$TIME <- byStorm$TIMESTAMP
histDf$ID <- byStorm$ID
meltedHist <- melt(histDf, id.vars = c("ID", "TIME"))
ggplot(meltedHist, aes(x = TIME, y = value, color = factor(ID) )) +
  geom_line(aes(group = variable)) +
  facet_grid(~variable) +
  scale_color_manual(values = pal) +
  theme_bw()+
  theme(legend.position = "none", axis.text.x = element_text(angle = 50))
goodStorms <- byStorm[ -(which(byStorm$ID %in% c("AL102002", "AL122000", "AL132002", "AL142011", "AL142012", "AL162011", "AL022004", "AL042001", "AL072011"))), ]
areTheyIncreasing <- byStorm[, grep("HIST*", colnames(byStorm))]
areTheyIncreasing$ID <- byStorm$ID
areTheyIncreasing$DATE <- byStorm$DATE
areTheyIncreasing$TIME <- byStorm$TIMESTAMP
checks <- areTheyIncreasing %>% group_by(ID) %>% arrange(TIME) %>% mutate(diff20 = (HIST20 - lag(HIST20)), diff25 = (HIST25 - lag(HIST25)), diff30 = (HIST30 - lag(HIST30)), diff35 = (HIST35 - lag(HIST35)), diff40 = (HIST40 - lag(HIST40)), diff45 = (HIST45 - lag(HIST45)), diff50 = (HIST50 - lag(HIST50)), diff55 = (HIST55 - lag(HIST55)), diff60 = (HIST60 - lag(HIST60)), diff65 = (HIST65 - lag(HIST65)), diff70 = (HIST70 - lag(HIST70)), diff75 = (HIST75 - lag(HIST75)), diff80 = (HIST80 - lag(HIST80)), diff85 = (HIST85 - lag(HIST85)), diff90 = (HIST90 - lag(HIST90)), diff95 = (HIST95 - lag(HIST95)), diff100 = (HIST100 - lag(HIST100)), diff105 = (HIST105 - lag(HIST105)), diff110 = (HIST110 - lag(HIST110)), diff115 = (HIST115 - lag(HIST115)), diff120 = (HIST120 - lag(HIST120)))

``` 

Checking numerically by row that the history variables are different by either 1 or 0 from the previous variable observation by storm, we find a total of 16 storms with history issues, including the 9 storms with time point inconsistencies. These storm IDs,

```{r, echo = FALSE}
p <- which(checks[, c(25:ncol(checks))] != 0 & checks[, c(25:ncol(checks))] != 1, arr.ind = TRUE)
problems <- unique(p[,1])
troubles = byStorm[problems, ]
realProblems <- subset(troubles, Match == TRUE)
realProblems$ID
```

show history inconsistencies, which under further investigation, is a result of date inconsistencies. As it would happen, this data set only includes cases that qualify as tropical or sub-tropical storms. If the storm weakens, it is no longer classified into either of these two categories and the data is no longer available. If the storm picks up speed, the tracking resumes explaining what happened to NADINE and the history inconsistent storms. A small note, there are also inconsistencies between storms in the case-dependent **TYPE** and **REFC** attributes. Without these variables included in the checks and accounting for missing dates, all inconsistencies are resolved.

### VMAX and TIME
The storm instances have a binary label, 1 indicating RI and 0 indicating nonRI (for any increase in windspeed greater than 30 kts within 24 hrs), in addition to a VMAX_Diff column that measures the future 24 hour change in intensity relative to the current time point. An `NA` in the **RI** and **VMAXDiff** column signify that the data are not available for the timepoints needed to calculate these attributes (storms like NADINE). The distribution of maximum intensities per time interval for the nonRI and RI storms are shown below. Keep in mind that NAs are likely equivalent to nonRI events as the storm has weakened. 

### VMAX
```{r, echo = FALSE, message = FALSE}
byIndex <- byStorm %>% group_by(RI)

RI_labeller <- function(var, value){
    value <- as.character(value)
    if (var == "RI") { 
        value[value == "1"] <- "RI"
        value[value == "0"]   <- "nonRI"
    }
    return(value)
}

ggplot(byIndex, aes(VMAX)) +
  geom_histogram() +
  facet_grid(~RI, labeller = RI_labeller)
```

In terms of class imbalance, there are ``r sum(na.omit(byIndex$RI == 1))`` RI instances compared to ``r sum(na.omit(byIndex$RI == 0))`` nonRI instances. The VMAX Diff shown below ranges from `r min(byIndex$VMAX_Diff)` to `r max(byIndex$VMAX_Diff)`.

```{r, echo = FALSE, message = FALSE}
ggplot(byIndex, aes(x = VMAX_Diff, fill = factor(RI))) +
  geom_histogram() +
  scale_fill_manual(values = c("#999999", "#FF0000"), name = "Label", breaks = c(0,1), labels = c("nonRI", "RI"))
```

### Time Component
```{r, echo = FALSE, message = FALSE}
byStormSummary <- byStorm %>% summarise(nObs = (last(TIMESTAMP) - first(TIMESTAMP))/dhours(1), RI_Label = sum(na.omit(RI)))
```
The longest storm in the data is ``r byStormSummary[which.max(byStormSummary$nObs), "ID"]`` lasting a total of ``r max(byStormSummary$nObs)`` hours. The shortest storm is  ``r byStormSummary[which.min(byStormSummary$nObs), "ID"]`` lasting a total of ``r min(byStormSummary$nObs)`` hours. The distribution of storm duration for all storms, colored by the number of RI events in each storm, looks like:

```{r, echo = FALSE, message = FALSE}

p <- rev(wes_palette("Darjeeling", n = 12, type = "continuous") )
ggplot(byStormSummary, aes(x = nObs, fill = factor(RI_Label))) +
  geom_bar() +
  ggtitle("Storm Lengths and RI Instances") +
  xlab("Storm Length in Hours") +
  scale_fill_manual(values = p, name = "RI Instances", breaks = c(0,1,2,3,4,5,6,7,8,9,10,11))
```

In terms of the time series view, a snapshot look at VMAX vs TIME:

```{r, echo = FALSE, message = FALSE, fig.height = 6, fig.width= 10}
nonRIFour <- subset(byStorm, ID %in% c("AL011988", "AL012001", "AL011999", "AL011994"))
nonRI <- nonRIFour %>% group_by(ID) %>% mutate(TIME = cumsum(hour(TIMESTAMP)))
#q <- wes_palette("Zissou")
a1 <- ggplot(nonRI, aes(x = TIME, y = VMAX, color = ID)) +
  geom_line() +
  coord_cartesian(ylim = c(0, 170)) + 
  ggtitle("NonRI Storms Max Windspeed v Time") +
  xlab("Hours Relative to Midnight of Storm Start Day") 
  #scale_color_manual(values = q, name = "ID", breaks = c(0,1,2,3,4))

RIFour <- subset(byStorm, ID %in% c("AL011982", "AL022008", "AL051992", "AL081988"))
rRI <- RIFour %>% group_by(ID) %>% mutate(TIME = cumsum(hour(TIMESTAMP)))

a2 <- ggplot(rRI, aes(x = TIME, y = VMAX, color = ID)) +
  geom_line() +
  coord_cartesian(ylim = c(0, 170)) + 
  ggtitle("RI Storms Max Windspeed v Time") +
  xlab("Hours Relative to Midnight of Storm Start Day")
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

multiplot(a1, a2, cols=2)
```

Similarly, the 24 change in maximum windspeed varies widely for the storms that contain RI events.

```{r, echo = FALSE, message = FALSE, fig.height = 6, fig.width= 10}
b1 <- ggplot(nonRI, aes(x = TIME, y = VMAX_Diff, color = ID)) +
  geom_line() +
  coord_cartesian(ylim = c(-80, 70)) + 
  geom_hline(aes(yintercept = 30))+
  ggtitle("NonRI Storms 24 Hour Change in  Windspeed") +
  xlab("Hours Relative to Midnight of Storm Start Day")

b2 <- ggplot(rRI, aes(x = TIME, y = VMAX_Diff, color = ID)) +
  geom_line() +
  coord_cartesian(ylim = c(-80, 70)) + 
  geom_hline(aes(yintercept = 30))+
  ggtitle("RI Storms 24 Hour Change in  Windspeed")+
  xlab("Hours Relative to Midnight of Storm Start Day")
multiplot(b1, b2, cols = 2)
```

```{r, echo = FALSE, message = FALSE}
library(lubridate)
byStorm$JDAY <- abs(yday(byStorm$DATE) - 253)
byStorm$POT <- byStorm$VMPI - byStorm$VMAX #66.5 + 108.5*exp(0.1813*(byStorm$SST/10 - 30))
write.csv(byStorm, file = "~/Documents/Projects/TeMpSA/TeMpSA/SHIPS_Developmental/tcData.csv", row.names = FALSE)
names(byStorm[4]) = "RECORDNUM"
save(byStorm, file = "~/Documents/Projects/TeMpSA/TeMpSA/SHIPS_Developmental/tcData.RData")
```

## Dissipating Stroms

```{r, echo = FALSE, message = FALSE}

timeTest <- byStorm %>% mutate(TimeLag = lag(TIMESTAMP))
timeTest$Diff <- (timeTest$TIMESTAMP - timeTest$TimeLag)/ dhours(6)
dissStormIDs <- timeTest$ID[which(timeTest$Diff != 1)]
dissipatingStorms <- timeTest %>% filter(ID %in% dissStormIDs)
```

Dealing specifically with storms where we have missing data because of dissipation, there are exactly ``r length(unique(dissStormIDs))`` dissipating storms out of ``r length(unique(byStorm$ID))`` total storms. The dissipating storms are plotted below

```{r, echo = FALSE, message = FALSE, fig.height = 10, fig.width = 9.5}
library(wesanderson)
palette = wes_palette("Royal1", n = 19, type = "continuous")
palette[1] = "#000001"
ggplot(dissipatingStorms, aes(x = TIMESTAMP, y = VMAX)) +
  geom_line() +
  geom_point(aes(color = factor(Diff)), size = 2) +
  scale_color_manual(values = palette) +
  facet_wrap(~ID, scale = 'free') + 
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
  
```

## Missing Data

```{r, echo = FALSE}
dissStormIDs <- timeTest$ID[which(timeTest$Diff != 1)]
tc1983set <-  byStorm %>% filter(!(ID %in% dissStormIDs)) %>% filter(TIMESTAMP <= parse_date_time(1983, "y")) %>% select(-c(RecordNum, RI, VMAX_Diff, Match))
tcPost83set <- byStorm %>% filter(!(ID %in% dissStormIDs)) %>% filter(TIMESTAMP > parse_date_time(1995, "y")) %>% select(-c(RecordNum, RI, VMAX_Diff, Match))
```

To summarize the amount of missing data in each of the attributes, we first subset to the timepoints with and with GOES satellite information available. As of March 2009, the satellites were backfilled to 1983, whereas they were only available from 1995 previously. A summary of the `r length(unique(tc1983set$ID))` storms up to 1983:

```{r, echo = FALSE, fig.width=9.5, fig.height = 10}
library(d3heatmap)
res <- list()
tcData <- tc1983set
for (i in 1:length(unique(tcData$ID))) { 
  storm <- unique(tcData$ID)[i]
  temp <- subset(tcData, ID == storm)
  nMissing <- lapply(temp, function(x) sum(is.na(x)))
  res[[i]] <- data.frame(nObs = length(temp$ID), totalMissing = sum(is.na(temp)), nMissing = nMissing)
} 
summaryData <- do.call(rbind, res)
rownames(summaryData) <- (unique(tcData$ID)) 
#summary(summaryData)
d3heatmap(summaryData[,-c(1:2)], dendrogram = "none", color = "Blues", cexCol = 0.25, cexRow = 0.5)
```

And a summary of the `r length(unique(tcPost83set$ID))` storms post 1983:

```{r, echo = FALSE, fig.width=9.5, fig.height = 10}

res <- list()
tcData <- tcPost83set
for (i in 1:length(unique(tcData$ID))) { 
  storm <- unique(tcData$ID)[i]
  temp <- subset(tcData, ID == storm)
  nMissing <- lapply(temp, function(x) sum(is.na(x)))
  res[[i]] <- data.frame(nObs = length(temp$ID), totalMissing = sum(is.na(temp)), nMissing = nMissing)
} 
summaryData <- do.call(rbind, res)
rownames(summaryData) <- (unique(tcData$ID)) 
#summary(summaryData)
d3heatmap(summaryData[,-c(1:2)], dendrogram = "none", color = "Blues", cexCol = 0.25, cexRow = 0.5)
```

To drill down specifically, the largest amount of missing data comes from satellites, with ``r length(which(summaryData$nMissing.IRM3_AVG_30BT > 0))`` of the  `r length(unique(tcPost83set$ID))` post `83 storms missing *IR* information.

# References

